{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3046e95",
   "metadata": {},
   "source": [
    "# <center> Simple Face Detection using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b49b1",
   "metadata": {},
   "source": [
    "#### Objective:\n",
    "The objective of this project is to create a real-time face detection system using Python and OpenCV. The program captures video frames from the default camera, converts each frame to grayscale, and then applies a pre-trained Haar Cascade classifier to detect faces within the frame. Detected faces are outlined with rectangles, providing a visual indication of their location in the video stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660a875",
   "metadata": {},
   "source": [
    "#### How is it relevant?\n",
    "\n",
    "The project serves as a basic example of how to use computer vision techniques for face detection. Face detection is a fundamental step in many computer vision applications, including facial recognition, emotion detection, and more. The Haar Cascade classifier used in this project is a machine learning-based approach for object detection, particularly well-suited for detecting faces.\n",
    "\n",
    "Users can run this script to see a live demonstration of face detection through their webcam, and the script can be extended or integrated into more complex applications for various purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b89c10",
   "metadata": {},
   "source": [
    "**1. Importing Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06844eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ad7b0",
   "metadata": {},
   "source": [
    "\n",
    "- **cv2:**\n",
    "   - cv2 stands for OpenCV (Open Source Computer Vision Library), and it is a powerful library for computer vision and image processing tasks.\n",
    "   - OpenCV provides various functions and tools for image and video processing, including reading and writing image files, image manipulation, feature detection, and object recognition.\n",
    "   - In the given code, cv2 is used for capturing video frames from the camera, converting frames to grayscale, and performing face detection using a Haar Cascade classifier.\n",
    "   \n",
    "- **pathlib:** \n",
    "    - pathlib is a module introduced in Python 3.4 as part of the standard library. It provides an object-oriented interface for file system paths.\n",
    "    - This module simplifies working with file paths and avoids the need for string manipulation when dealing with file and directory paths.\n",
    "    - In the given code, pathlib is used to create a platform-independent file path for the Haar Cascade classifier XML file. The Path class is used to represent and manipulate file system paths, and it helps in constructing the full path to the Haar Cascade XML file by combining the OpenCV library path and the relative path to the classifier file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92615bb",
   "metadata": {},
   "source": [
    "**2. Setting Haar Cascade Path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "585a91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "cascade_path = pathlib.Path(cv2.__file__).parent.absolute() / \"data/haarcascade_frontalface_default.xml\"\n",
    "print(cascade_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba12c26",
   "metadata": {},
   "source": [
    "- cv2.__file__:\n",
    "\n",
    "     - cv2 is the OpenCV library.\n",
    "     - cv2.__file__ returns the path to the cv2 module file.\n",
    "\n",
    "- pathlib.Path(cv2.__file__):\n",
    "\n",
    "     - pathlib.Path is used to create a Path object representing the path to the cv2 module file.\n",
    "     \n",
    "- .parent:\n",
    "\n",
    "     - .parent is an attribute of the Path object, and it returns the parent directory of the current path.\n",
    "     \n",
    "- .absolute():\n",
    "\n",
    "     - .absolute() returns an absolute version of the path, ensuring that the full path is used.\n",
    "     \n",
    "- / \"data/haarcascade_frontalface_default.xml\":\n",
    "\n",
    "     - / is the path concatenation operator. It combines the absolute path of the parent directory with the relative path to the Haar Cascade XML file.\n",
    "     - This assumes that there is a directory named \"data\" in the same directory as the cv2 module, and within that directory, there is a file named \"haarcascade_frontalface_default.xml\".\n",
    "\n",
    "- cascade_path:\n",
    "\n",
    "     - The result is assigned to the variable cascade_path, which now holds the full path to the Haar Cascade XML file.\n",
    "\n",
    "- print(cascade_path):\n",
    "\n",
    "     - This prints the constructed path to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203812d6",
   "metadata": {},
   "source": [
    "**3. Creating Cascade Classifier and setting up the camera:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667caeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cv2.CascadeClassifier(str(cascade_path))\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d47c96",
   "metadata": {},
   "source": [
    "- clf = cv2.CascadeClassifier(str(cascade_path)):\n",
    "\n",
    "   - This line creates a CascadeClassifier object (clf) using the Haar Cascade XML file specified by cascade_path.\n",
    "   - The CascadeClassifier class in OpenCV is used for object detection, and in this case, it's configured for frontal face detection. The XML file contains the trained parameters for the face detection algorithm.\n",
    "\n",
    "- camera = cv2.VideoCapture(0):\n",
    "\n",
    "    - This line creates a VideoCapture object (camera) to capture video frames from a video source.\n",
    "    - The argument 0 indicates that the default camera (camera index 0) should be used. If you have multiple cameras, you can change the index accordingly (e.g., cv2.VideoCapture(1) for the second camera).\n",
    "    - The VideoCapture object is crucial for continuously capturing frames from the camera, allowing the face detection algorithm to process each frame in real-time.\n",
    "\n",
    "Together, these two lines set up the face detection system by loading the Haar Cascade classifier and initializing the video capture from the default camera. Subsequently, the script enters a loop where it captures frames from the camera, performs face detection, and displays the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd803d0",
   "metadata": {},
   "source": [
    "Here, we are dealing with different aspects of the project at once:\n",
    "\n",
    "**4. Face Detection Loop**\n",
    "**5. Drawing Rectangles Around Detected Faces**\n",
    "**6. Displaying the Result**\n",
    "**7. Exiting the Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac982e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = camera.read()\n",
    "    gray = cv2.cvtColor(frame , cv2.COLOR_BGR2GRAY)\n",
    "    faces = clf.detectMultiScale(gray , scaleFactor = 1.1 , minNeighbors = 5 , minSize = (30,30) , flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    for (x , y , width , height) in faces:\n",
    "        cv2.rectangle(frame , (x,y) , (x+width , y+height) , (255,255,0) , 2)\n",
    "        \n",
    "    cv2.imshow(\"Faces\" , frame)\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cf0be",
   "metadata": {},
   "source": [
    "- while True::\n",
    "\n",
    "   - The infinite loop continues to capture frames and perform face detection until manually terminated.\n",
    "\n",
    "- _, frame = camera.read():\n",
    "\n",
    "   - It reads a frame from the video source (camera), and the frame is stored in the variable frame.\n",
    "\n",
    "- gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY):\n",
    "\n",
    "   - Converts the color frame (frame) to grayscale (gray) for efficient face detection.\n",
    "\n",
    "- faces = clf.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE):\n",
    "\n",
    "   - Detects faces in the grayscale frame using the Haar Cascade classifier (clf). The detected faces are represented as rectangles, and their coordinates are stored in the faces variable.\n",
    "\n",
    "- for (x, y, width, height) in faces::\n",
    "\n",
    "   - Iterates over the list of detected faces (faces) and extracts the coordinates (x, y) of the top-left corner and the dimensions (width, height) of each face.\n",
    "\n",
    "- cv2.rectangle(frame, (x, y), (x + width, y + height), (255, 255, 0), 2):\n",
    "\n",
    "   - Draws a rectangle around each detected face on the original color frame (frame).\n",
    "   - The rectangle is drawn using the cv2.rectangle function with parameters for the top-left and bottom-right corners, color (in BGR format), and thickness.\n",
    "\n",
    "- cv2.imshow(\"Faces\", frame):\n",
    "\n",
    "   - Displays the frame with rectangles drawn around the detected faces in a window titled \"Faces\".\n",
    "\n",
    "- if cv2.waitKey(1) == ord(\"q\"): break:\n",
    "\n",
    "   - Waits for a key event. If the key pressed is \"q\", the loop breaks, and the program terminates.\n",
    "\n",
    "This code essentially creates a real-time face detection application where each frame from the camera is processed, faces are detected, rectangles are drawn around them, and the resulting video stream is continuously displayed. Pressing the \"q\" key exits the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d46da5",
   "metadata": {},
   "source": [
    "**8. Releasing Resources:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc2ec9",
   "metadata": {},
   "source": [
    "- camera.release():\n",
    "\n",
    "   - This line releases the video capture object (camera). When you are done using the camera or video file, it's good practice to release the associated resources. This ensures that the camera is properly closed and available for other applications or processes.\n",
    "   \n",
    "- cv2.destroyAllWindows():\n",
    "\n",
    "    - This line closes all OpenCV windows that were created during the execution of the script. In your specific code, a window titled \"Faces\" was created using cv2.imshow(\"Faces\", frame). The cv2.destroyAllWindows() call ensures that this window (and any other open windows) is closed when the script is terminated.\n",
    "\n",
    "These lines are typically placed at the end of a script to clean up resources and close any windows that were opened during the execution. Failure to release resources properly may lead to issues, especially when dealing with camera devices or multiple OpenCV windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6406db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
